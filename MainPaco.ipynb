{"cells":[{"source":["import os \n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","import TinySleepNet\n","import wandb\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import DatasetsPaco"],"cell_type":"code","metadata":{},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# wandb.init()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["binary_labels = True\n","channels = ['F4']\n","batch_size = 32"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["prueba = DatasetsPaco.EDFData_GEN_TF(\"/home/jorgevi/SSD_IA3/Data/PSG1.edf\", channels=channels)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def our_generator():\n","    for x, y in prueba:\n","      yield x, y\n","\n","dataset = tf.data.Dataset.from_generator(our_generator, (tf.float64, tf.int32)).batch(32).shuffle(64) # tf.int16 => tf.int32, tf.float32 => tf.float64"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<tf.Tensor: shape=(32, 15360, 1), dtype=float64, numpy=\n"," array([[[-1.92014534],\n","         [-1.61724675],\n","         [-1.59561114],\n","         ...,\n","         [ 1.5631884 ],\n","         [ 1.54155279],\n","         [ 1.08720491]],\n"," \n","        [[ 1.62809524],\n","         [ 1.95262944],\n","         [ 1.77954454],\n","         ...,\n","         [ 1.00066246],\n","         [ 0.43813651],\n","         [ 0.50304335]],\n"," \n","        [[ 0.30832283],\n","         [-0.34074557],\n","         [-0.47055925],\n","         ...,\n","         [-0.8816359 ],\n","         [-0.75182222],\n","         [-0.38401679]],\n"," \n","        ...,\n"," \n","        [[ 0.61122142],\n","         [ 0.24341599],\n","         [ 0.50304335],\n","         ...,\n","         [-1.55233991],\n","         [-0.96817835],\n","         [-0.83836467]],\n"," \n","        [[ 0.04869547],\n","         [ 0.02705986],\n","         [-0.10275382],\n","         ...,\n","         [ 0.67612826],\n","         [ 1.43337472],\n","         [ 2.55842662]],\n"," \n","        [[ 2.88296082],\n","         [ 1.93099383],\n","         [ 1.15211175],\n","         ...,\n","         [ 1.3901035 ],\n","         [ 1.5631884 ],\n","         [ 1.67136647]]])>,\n"," <tf.Tensor: shape=(32,), dtype=int32, numpy=\n"," array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>)"]},"metadata":{},"execution_count":6}],"source":["next(iter(dataset))"]},{"cell_type":"markdown","metadata":{},"source":["train data"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# train_dataset = DatasetsPaco.EDFData_TF_old(\"/home/jorgevi/SSD_IA3/Data/PSG1.edf\", batch_size=batch_size, channels=channels,\n","#                                                       binary_labels=binary_labels)\n","# labels_b = []\n","# for a, b in train_dataset:\n","#     labels_b.extend(b)\n","\n","# X_binary_std = []\n","# for X, Y in train_dataset:\n","#     X_binary_std.append(X)\n","# X_binary_std = np.vstack(X_binary_std)\n","\n","# tftraindatasetmemo = tf.data.Dataset.from_tensor_slices(\n","#     (tf.convert_to_tensor(X_binary_std), tf.convert_to_tensor(labels_b))).batch(32).shuffle(64)\n","\n","# for x, y in train_dataset:\n","#     print(x, y)\n","#     break"]},{"cell_type":"markdown","metadata":{},"source":["test data"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# test_dataset = DatasetsPaco.EDFData_TF_old(\"/home/jorgevi/SSD_IA3/Data/PSG5.edf\", batch_size=batch_size, channels=channels,\n","#                                                      binary_labels=binary_labels)\n","# labels_test = []\n","# for a, b in test_dataset:\n","#     labels_test.extend(b)\n","\n","# X_binary_std_test = []\n","# for X, Y in test_dataset:\n","#     X_binary_std_test.append(X.numpy())\n","# X_binary_std_test = np.vstack(X_binary_std_test)\n","\n","# tftestdatasetmemo = tf.data.Dataset.from_tensor_slices(\n","#     (tf.convert_to_tensor(X_binary_std_test), tf.convert_to_tensor(labels_test))).batch(32).shuffle(64)"]},{"cell_type":"markdown","metadata":{},"source":["model train and validation"]},{"source":["sr = int(prueba.sampling_rate)\n","num_epochs = 10\n","if binary_labels:\n","    classes = 2\n","else:\n","    classes = 5"],"cell_type":"code","metadata":{},"execution_count":13,"outputs":[]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["model = TinySleepNet.TinySleepNet(sr, len(channels), classes)"]},{"cell_type":"markdown","metadata":{},"source":["Keep results for plotting"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["train_loss_results = []\n","train_accuracy_results = []\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n","loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 000: Loss: 0.571, Accuracy: 76.190%\n","Epoch 001: Loss: 0.801, Accuracy: 52.154%\n","Epoch 002: Loss: 0.670, Accuracy: 72.109%\n","Epoch 003: Loss: 0.640, Accuracy: 72.109%\n","Epoch 004: Loss: 0.613, Accuracy: 72.109%\n","Epoch 005: Loss: 0.613, Accuracy: 71.882%\n","Epoch 006: Loss: 0.606, Accuracy: 71.995%\n","Epoch 007: Loss: 0.603, Accuracy: 71.769%\n","Epoch 008: Loss: 0.603, Accuracy: 71.882%\n","Epoch 009: Loss: 0.598, Accuracy: 71.995%\n"]}],"source":["for epoch in range(num_epochs):\n","    epoch_loss_avg = tf.keras.metrics.Mean()\n","    epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n","    for x, y in dataset:\n","        with tf.GradientTape() as tape:\n","            y_ = model(x)\n","            loss = loss_fn(y, y_)\n","        grads = tape.gradient(loss, model.trainable_variables)\n","        # wandb.log({'gradients': grads})\n","        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","\n","        # Track progress\n","        epoch_loss_avg.update_state(loss)  # loss = loss.numpy()\n","        epoch_accuracy.update_state(y, y_)\n","\n","    # End epoch\n","    train_loss_results.append(epoch_loss_avg.result())\n","    train_accuracy_results.append(epoch_accuracy.result())\n","    # wandb.log({'epoch_loss': epoch_loss_avg.result().numpy(), 'epoch_accuracy': epoch_accuracy.result().numpy()})\n","    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n","                                                                epoch_loss_avg.result(),\n","                                                                epoch_accuracy.result()))"]},{"source":["# model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n","# history = model.fit(dataset, epochs=num_epochs, batch_size=32)\n","# model.summary()\n","\n","# plt.plot(history.history['acc'])\n","# plt.plot(history.history['loss'])\n","# plt.savefig('train')\n","\n","# ValueError: as_list() is not defined on an unknown TensorShape."],"cell_type":"code","metadata":{},"execution_count":17,"outputs":[]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["# test_accuracy = tf.keras.metrics.Accuracy()\n","# for x, y in tftestdatasetmemo:\n","#     logits = model(x)\n","#     predictions = tf.argmax(logits, axis=1, output_type=tf.int32)\n","#     test_accuracy(predictions, y)\n","# print(\"Test set accuracy: {:.3%}\".format(test_accuracy.result()))"]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.9.5 64-bit ('ssd_tfm': conda)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"interpreter":{"hash":"a669df6e687335fd4d765959bdd3254608186c822431811e98b0b1dce9ff2416"}},"nbformat":4,"nbformat_minor":2}