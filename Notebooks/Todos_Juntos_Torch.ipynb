{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd057d46a1f3f975f92cc34d815bf69a7d3644582cc16f1cedc66cb95f17202c91e",
   "display_name": "Python 3.8.5 64-bit ('Master': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import mne\n",
    "mne.set_log_level(verbose=False)\n",
    "\n",
    "from Datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "channels = ['F4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "e:\\Python\\TFM\\SSD_IA3\\Notebooks\\Datasets.py:18: RuntimeWarning: Omitted 3 annotation(s) that were outside data range.\n",
      "  data = mne.io.read_raw_edf(path)\n",
      "e:\\Python\\TFM\\SSD_IA3\\Notebooks\\Datasets.py:18: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  data = mne.io.read_raw_edf(path)\n",
      "e:\\Python\\TFM\\SSD_IA3\\Notebooks\\Datasets.py:18: RuntimeWarning: Omitted 109 annotation(s) that were outside data range.\n",
      "  data = mne.io.read_raw_edf(path)\n",
      "e:\\Python\\TFM\\SSD_IA3\\Notebooks\\Datasets.py:18: RuntimeWarning: Omitted 92 annotation(s) that were outside data range.\n",
      "  data = mne.io.read_raw_edf(path)\n",
      "e:\\Python\\TFM\\SSD_IA3\\Notebooks\\Datasets.py:18: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  data = mne.io.read_raw_edf(path)\n",
      "e:\\Python\\TFM\\SSD_IA3\\Notebooks\\Datasets.py:18: RuntimeWarning: Omitted 120 annotation(s) that were outside data range.\n",
      "  data = mne.io.read_raw_edf(path)\n",
      "e:\\Python\\TFM\\SSD_IA3\\Notebooks\\Datasets.py:18: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  data = mne.io.read_raw_edf(path)\n",
      "e:\\Python\\TFM\\SSD_IA3\\Notebooks\\Datasets.py:18: RuntimeWarning: Omitted 2 annotation(s) that were outside data range.\n",
      "  data = mne.io.read_raw_edf(path)\n",
      "e:\\Python\\TFM\\SSD_IA3\\Notebooks\\Datasets.py:18: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  data = mne.io.read_raw_edf(path)\n",
      "e:\\Python\\TFM\\SSD_IA3\\Notebooks\\Datasets.py:18: RuntimeWarning: Omitted 104 annotation(s) that were outside data range.\n",
      "  data = mne.io.read_raw_edf(path)\n",
      "e:\\Python\\TFM\\SSD_IA3\\Notebooks\\Datasets.py:18: RuntimeWarning: Limited 2 annotation(s) that were expanding outside the data range.\n",
      "  data = mne.io.read_raw_edf(path)\n",
      "e:\\Python\\TFM\\SSD_IA3\\Notebooks\\Datasets.py:18: RuntimeWarning: Omitted 6 annotation(s) that were outside data range.\n",
      "  data = mne.io.read_raw_edf(path)\n",
      "e:\\Python\\TFM\\SSD_IA3\\Notebooks\\Datasets.py:18: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  data = mne.io.read_raw_edf(path)\n",
      "e:\\Python\\TFM\\SSD_IA3\\Notebooks\\Datasets.py:18: RuntimeWarning: Omitted 2 annotation(s) that were outside data range.\n",
      "  data = mne.io.read_raw_edf(path)\n",
      "e:\\Python\\TFM\\SSD_IA3\\Notebooks\\Datasets.py:18: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  data = mne.io.read_raw_edf(path)\n",
      "e:\\Python\\TFM\\SSD_IA3\\Notebooks\\Datasets.py:18: RuntimeWarning: Omitted 39 annotation(s) that were outside data range.\n",
      "  data = mne.io.read_raw_edf(path)\n",
      "e:\\Python\\TFM\\SSD_IA3\\Notebooks\\Datasets.py:18: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  data = mne.io.read_raw_edf(path)\n",
      "e:\\Python\\TFM\\SSD_IA3\\Notebooks\\Datasets.py:18: RuntimeWarning: Omitted 143 annotation(s) that were outside data range.\n",
      "  data = mne.io.read_raw_edf(path)\n",
      "e:\\Python\\TFM\\SSD_IA3\\Notebooks\\Datasets.py:18: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  data = mne.io.read_raw_edf(path)\n",
      "e:\\Python\\TFM\\SSD_IA3\\Notebooks\\Datasets.py:18: RuntimeWarning: Omitted 234 annotation(s) that were outside data range.\n",
      "  data = mne.io.read_raw_edf(path)\n",
      "e:\\Python\\TFM\\SSD_IA3\\Notebooks\\Datasets.py:18: RuntimeWarning: Limited 3 annotation(s) that were expanding outside the data range.\n",
      "  data = mne.io.read_raw_edf(path)\n",
      "e:\\Python\\TFM\\SSD_IA3\\Notebooks\\Datasets.py:18: RuntimeWarning: Omitted 113 annotation(s) that were outside data range.\n",
      "  data = mne.io.read_raw_edf(path)\n",
      "e:\\Python\\TFM\\SSD_IA3\\Notebooks\\Datasets.py:18: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  data = mne.io.read_raw_edf(path)\n",
      "e:\\Python\\TFM\\SSD_IA3\\Notebooks\\Datasets.py:18: RuntimeWarning: Omitted 4 annotation(s) that were outside data range.\n",
      "  data = mne.io.read_raw_edf(path)\n",
      "e:\\Python\\TFM\\SSD_IA3\\Notebooks\\Datasets.py:18: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  data = mne.io.read_raw_edf(path)\n",
      "e:\\Python\\TFM\\SSD_IA3\\Notebooks\\Datasets.py:18: RuntimeWarning: Omitted 99 annotation(s) that were outside data range.\n",
      "  data = mne.io.read_raw_edf(path)\n",
      "e:\\Python\\TFM\\SSD_IA3\\Notebooks\\Datasets.py:18: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  data = mne.io.read_raw_edf(path)\n",
      "Wall time: 1min 14s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(14, 14, 11157, 2789)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "%%time\n",
    "datasets = [EDFData_PTH(path, channels=channels) for path in glob(\"../Data/*edf\")]\n",
    "dataset_together = torch.utils.data.ConcatDataset(datasets)\n",
    "dataloaders = [torch.utils.data.DataLoader(dataset, batch_size = BATCH_SIZE, drop_last=True) for dataset in datasets]\n",
    "dataloader_together = torch.utils.data.DataLoader(dataset_together, batch_size = BATCH_SIZE, drop_last=True)\n",
    "len(datasets), len(dataloaders), len(dataset_together), len(dataloader_together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<Epochs |  882 events (all good), 0 - 29.998 sec, baseline off, ~6 kB, data not loaded,\n 'Sleep stage N1': 25\n 'Sleep stage N2': 317\n 'Sleep stage N3': 193\n 'Sleep stage R': 101\n 'Sleep stage W': 246>\n<Epochs |  756 events (all good), 0 - 29.998 sec, baseline off, ~6 kB, data not loaded,\n 'Sleep stage N1': 14\n 'Sleep stage N2': 455\n 'Sleep stage N3': 114\n 'Sleep stage W': 173>\n<Epochs |  715 events (all good), 0 - 29.998 sec, baseline off, ~6 kB, data not loaded,\n 'Sleep stage N1': 4\n 'Sleep stage N2': 248\n 'Sleep stage N3': 185\n 'Sleep stage R': 93\n 'Sleep stage W': 185>\n<Epochs |  764 events (all good), 0 - 29.998 sec, baseline off, ~6 kB, data not loaded,\n 'Sleep stage N1': 14\n 'Sleep stage N2': 403\n 'Sleep stage N3': 218\n 'Sleep stage R': 94\n 'Sleep stage W': 35>\n<Epochs |  805 events (all good), 0 - 29.998 sec, baseline off, ~6 kB, data not loaded,\n 'Sleep stage N1': 127\n 'Sleep stage N2': 293\n 'Sleep stage N3': 169\n 'Sleep stage R': 86\n 'Sleep stage W': 130>\n<Epochs |  780 events (all good), 0 - 29.998 sec, baseline off, ~6 kB, data not loaded,\n 'Sleep stage N1': 67\n 'Sleep stage N2': 448\n 'Sleep stage N3': 37\n 'Sleep stage R': 12\n 'Sleep stage W': 216>\n<Epochs |  840 events (all good), 0 - 29.998 sec, baseline off, ~6 kB, data not loaded,\n 'Sleep stage N1': 63\n 'Sleep stage N2': 388\n 'Sleep stage N3': 235\n 'Sleep stage R': 136\n 'Sleep stage W': 18>\n<Epochs |  853 events (all good), 0 - 29.998 sec, baseline off, ~6 kB, data not loaded,\n 'Sleep stage N1': 145\n 'Sleep stage N2': 365\n 'Sleep stage N3': 219\n 'Sleep stage R': 86\n 'Sleep stage W': 38>\n<Epochs |  762 events (all good), 0 - 29.998 sec, baseline off, ~6 kB, data not loaded,\n 'Sleep stage N1': 35\n 'Sleep stage N2': 334\n 'Sleep stage N3': 209\n 'Sleep stage R': 69\n 'Sleep stage W': 115>\n<Epochs |  738 events (all good), 0 - 29.998 sec, baseline off, ~6 kB, data not loaded,\n 'Sleep stage N1': 85\n 'Sleep stage N2': 370\n 'Sleep stage N3': 146\n 'Sleep stage R': 34\n 'Sleep stage W': 103>\n<Epochs |  813 events (all good), 0 - 29.998 sec, baseline off, ~6 kB, data not loaded,\n 'Sleep stage N1': 143\n 'Sleep stage N2': 392\n 'Sleep stage N3': 76\n 'Sleep stage R': 25\n 'Sleep stage W': 177>\n<Epochs |  760 events (all good), 0 - 29.998 sec, baseline off, ~6 kB, data not loaded,\n 'Sleep stage N1': 13\n 'Sleep stage N2': 405\n 'Sleep stage N3': 94\n 'Sleep stage R': 57\n 'Sleep stage W': 191>\n<Epochs |  853 events (all good), 0 - 29.998 sec, baseline off, ~6 kB, data not loaded,\n 'Sleep stage N1': 15\n 'Sleep stage N2': 308\n 'Sleep stage N3': 419\n 'Sleep stage R': 74\n 'Sleep stage W': 37>\n<Epochs |  836 events (all good), 0 - 29.998 sec, baseline off, ~6 kB, data not loaded,\n 'Sleep stage N1': 36\n 'Sleep stage N2': 208\n 'Sleep stage N3': 286\n 'Sleep stage R': 64\n 'Sleep stage W': 242>\n\n"
     ]
    }
   ],
   "source": [
    "[print(dataset.epochs) for dataset in datasets]\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "sampling_rate = int(datasets[0].sampling_rate)\n",
    "sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinySleep(nn.Module):\n",
    "    def __init__(self, sampling_rate, channels):\n",
    "        super(TinySleep, self).__init__()\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.channels = channels\n",
    "\n",
    "        self.feature_extraction = nn.Sequential(*[\n",
    "            nn.Conv1d(in_channels=len(channels), out_channels=128, kernel_size=sampling_rate//2, stride=sampling_rate//4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=8, stride=8),\n",
    "            nn.Conv1d(in_channels=128, out_channels=128, kernel_size=8, stride=1, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=128, out_channels=128, kernel_size=8, stride=1, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=128, out_channels=128, kernel_size=8, stride=1, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        ])\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=128, hidden_size=128, batch_first=True)\n",
    "        \n",
    "        self.classifier = nn.Linear(2*128, 10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.feature_extraction(X)\n",
    "        X, _ = self.lstm(X.permute(0,2,1))\n",
    "        X = self.classifier(X.reshape(X.shape[0],-1))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TinySleep(\n",
       "  (feature_extraction): Sequential(\n",
       "    (0): Conv1d(1, 128, kernel_size=(256,), stride=(128,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv1d(128, 128, kernel_size=(8,), stride=(1,), padding=(3,))\n",
       "    (4): ReLU()\n",
       "    (5): Conv1d(128, 128, kernel_size=(8,), stride=(1,), padding=(3,))\n",
       "    (6): ReLU()\n",
       "    (7): Conv1d(128, 128, kernel_size=(8,), stride=(1,), padding=(3,))\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (lstm): LSTM(128, 128, batch_first=True)\n",
       "  (classifier): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "model = TinySleep(sampling_rate, channels)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 10])"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    pred = model(a)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 34 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "EPOCHS = 1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for X, Y in dataloader_together:\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, torch.squeeze(Y).long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([4, 10]), torch.Size([4, 1]))"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "pred.shape, Y.shape"
   ]
  }
 ]
}