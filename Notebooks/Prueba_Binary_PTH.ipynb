{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import mne\n",
    "mne.set_log_level(verbose=False)\n",
    "import wandb\n",
    "\n",
    "from Datasets import *\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjorgvt\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'epochs':50,\n",
    "    'classes':5,\n",
    "    'batch_size':32,\n",
    "    'learning_rate':0.001,\n",
    "    'channels':['C3','C4','O1','O2','LOC','ROC','CHIN1'],\n",
    "    'patients_train':1,\n",
    "    'patients_test':2,\n",
    "    'binary':True,\n",
    "    'metadata': \"Awake-Sleep test\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../Data/PSG1.edf\"\n",
    "test = EDFData_PTH(path, channels=config['channels'], binary=True)\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size = config['batch_size'], drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for X, Y in test:\n",
    "    labels.append(Y.item())\n",
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_rate = int(test.sampling_rate)\n",
    "sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinySleepNet(nn.Module):\n",
    "    def __init__(self, sampling_rate, channels, classes):\n",
    "        super(TinySleepNet, self).__init__()\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.channels = channels\n",
    "        self.classes = classes\n",
    "\n",
    "        self.feature_extraction = nn.Sequential(*[\n",
    "            nn.Conv1d(in_channels=len(channels), out_channels=128, kernel_size=sampling_rate//2, stride=sampling_rate//4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=8, stride=8),\n",
    "            nn.Conv1d(in_channels=128, out_channels=128, kernel_size=8, stride=1, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=128, out_channels=128, kernel_size=8, stride=1, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=128, out_channels=128, kernel_size=8, stride=1, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        ])\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=128, hidden_size=128, batch_first=True)\n",
    "        \n",
    "        self.classifier = nn.Linear(128*2, classes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.feature_extraction(X)\n",
    "        # X, _ = self.lstm(X.permute(0,2,1))\n",
    "        # X = X[:,-1,:]\n",
    "        X = X.view(X.shape[0],-1)\n",
    "        X = self.classifier(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TinySleepNet(\n",
       "  (feature_extraction): Sequential(\n",
       "    (0): Conv1d(7, 128, kernel_size=(256,), stride=(128,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv1d(128, 128, kernel_size=(8,), stride=(1,), padding=(3,))\n",
       "    (4): ReLU()\n",
       "    (5): Conv1d(128, 128, kernel_size=(8,), stride=(1,), padding=(3,))\n",
       "    (6): ReLU()\n",
       "    (7): Conv1d(128, 128, kernel_size=(8,), stride=(1,), padding=(3,))\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (lstm): LSTM(128, 128, batch_first=True)\n",
       "  (classifier): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TinySleepNet(sampling_rate, config['channels'], classes=len(test.id_to_class_dict))\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for X, Y in testloader:\n",
    "    X = X.to(device).float()\n",
    "    with torch.no_grad():\n",
    "        pap = model(X)\n",
    "    break\n",
    "pap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, loss_fn, history, X, Y, metrics=None):\n",
    "    \"\"\"\n",
    "    Trains the model over a batch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: nn.Module\n",
    "        Torch model.\n",
    "    optimizer:\n",
    "        Torch optimizer.\n",
    "    loss_fn:\n",
    "        Torch loss function.\n",
    "    X: torch.Tensor\n",
    "    Y: torch.Tensor\n",
    "    metrics: dict{str:functions}\n",
    "        Dict of functions (metrics) we want to calculate and their name.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    history: dict{str:float}\n",
    "        Dictionary of metrics.\n",
    "    \"\"\"\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(X)\n",
    "    loss = loss_fn(pred, Y)\n",
    "    loss.backward()\n",
    "\n",
    "    history['loss'] = loss.item()\n",
    "    if metrics:\n",
    "        with torch.no_grad():\n",
    "            for name, metric_fn in metrics.items():\n",
    "                history[name] = metric_fn(pred, Y)\n",
    "\n",
    "    optimizer.step()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_step(model, optimizer, loss_fn, history, X, Y, metrics=None):\n",
    "    \"\"\"\n",
    "    Calculates the validation metrics over a batch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: nn.Module\n",
    "        Torch model.\n",
    "    optimizer:\n",
    "        Torch optimizer.\n",
    "    loss_fn:\n",
    "        Torch loss function.\n",
    "    X: torch.Tensor\n",
    "    Y: torch.Tensor\n",
    "    metrics: dict{str:functions}\n",
    "        Dict of functions (metrics) we want to calculate and their name.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    history: dict{str:float}\n",
    "        Dictionary of metrics.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, Y)\n",
    "\n",
    "        history['val_loss'] = loss.item()\n",
    "        if metrics:\n",
    "            for name, metric_fn in metrics.items():\n",
    "                history['val_'+name] = metric_fn(pred, Y)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class History():\n",
    "    \"\"\"\n",
    "    Class designed to track the metrics during the training of a NN.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.history = {}\n",
    "\n",
    "    def update(self, history):\n",
    "        \"\"\"\n",
    "        Adds new values to the history.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        history: dict{str:float}\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        for metric_name, metric_value in history.items():\n",
    "            if metric_name not in self.history.keys():\n",
    "                self.history[metric_name] = [metric_value]\n",
    "            else:\n",
    "                self.history[metric_name].append(metric_value)\n",
    "\n",
    "    def return_lasts(self):\n",
    "        return {name:value[-1] for name, value in self.history.items()}\n",
    "        \n",
    "    \n",
    "    def plot_history(self, figsize=(16,6)):\n",
    "        \"\"\"\n",
    "        Plots the history values.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        history: History object\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        ## First retrieve metrics names ## \n",
    "        metrics_names = [a for a in self.history.keys() if a[:3]!='val']\n",
    "        \n",
    "        rows = 1\n",
    "        cols = len(metrics_names)\n",
    "\n",
    "        plt.figure(figsize=figsize)\n",
    "        for i,a in enumerate(metrics_names,1):\n",
    "            plt.subplot(rows,cols,i)\n",
    "            plt.title(a)\n",
    "            plt.plot(self.history[a], label=\"Train\")\n",
    "            plt.plot(self.history[\"val_\"+a], label=\"Validation\")\n",
    "            plt.legend()\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(Y_pred, Y_true):\n",
    "    \"\"\"\n",
    "    Calculates the accuracy of our model given its predictions and labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Y_pred: torch.Tensor\n",
    "        Raw output from the nn (logits).\n",
    "    Y_true: torch.Tensor\n",
    "        Objective labels.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    accuracy: float\n",
    "    \"\"\"\n",
    "    Y_pred = torch.softmax(Y_pred, dim=-1)\n",
    "    Y_pred = Y_pred.argmax(dim=-1)\n",
    "    accuracy = torch.where(Y_pred==Y_true, 1, 0).sum() / len(Y_true)\n",
    "\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Checkpoint():\n",
    "    \"\"\"Class that saves a model whenever a designated metric is improved.\"\"\"\n",
    "    \n",
    "    def __init__(self, path, monitor, mode='max', verbose=True):\n",
    "        \"\"\"\n",
    "        path: str\n",
    "            Path to save the model.\n",
    "        monitor: str\n",
    "            Name of the metric we want to monitor.\n",
    "            Has to be the same name as in the History object.\n",
    "        mode: str\n",
    "            Whether the best metric is the max or the min.\n",
    "        \"\"\"\n",
    "        assert mode in ['max', 'min'], 'mode must be either \"max\" or \"min\"'\n",
    "\n",
    "        self.path = path\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.verbose = verbose\n",
    "        self.best_metric = -999999 if self.mode=='max' else 999999\n",
    "        self.best_model = None\n",
    "\n",
    "    def step(self, model, metric):\n",
    "        if self.mode == 'max':\n",
    "            if metric > self.best_metric:\n",
    "                if self.verbose:\n",
    "                    print(f\"{self.monitor} improved from {self.best_metric:.4f} -> {metric:.4f}. Model saved!.\")\n",
    "\n",
    "                self.best_metric = metric\n",
    "                self.best_model = model\n",
    "                torch.save(model.state_dict(), self.path)\n",
    "\n",
    "        elif self.mode == 'min':\n",
    "            if metric < self.best_metric:\n",
    "                if self.verbose:\n",
    "                    print(f\"{self.monitor} improved from {self.best_metric:.4f} -> {metric:.4f}. Model saved!.\")\n",
    "\n",
    "                self.best_metric = metric\n",
    "                self.best_model = model\n",
    "                torch.save(model.state_dict(), self.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, loss_fn, trainloader, testloader, epochs, metrics, history=History, checkpoint=False, verbose=True):\n",
    "    ## Tell wandb to watch the model\n",
    "    wandb.watch(model, loss_fn, log=\"all\", log_freq=10)\n",
    "\n",
    "    history_epoch = history()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        history_batch = history()\n",
    "        for batch_i, (X, Y) in enumerate(trainloader, 1):\n",
    "            X, Y = X.to(device).float(), torch.squeeze(Y).long().to(device)\n",
    "            history_train = train_step(model, optimizer, loss_fn, {}, X, Y, metrics)\n",
    "            history_batch.update(history_train)\n",
    "            \n",
    "        for batch_i, (X, Y) in enumerate(testloader, 1):\n",
    "            X, Y = X.to(device).float(), torch.squeeze(Y).long().to(device)\n",
    "            history_val = val_step(model, optimizer, loss_fn, {}, X, Y, metrics)\n",
    "            history_batch.update(history_val)\n",
    "            \n",
    "        history_epoch.update({name:np.mean(values) for name,values in history_batch.history.items()})\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch+1} -> [Train] (Loss) {history_epoch.history['loss'][-1]:.4f} (Acc) {history_epoch.history['accuracy'][-1]:.4f} | [Val] (Loss) {history_epoch.history['val_loss'][-1]:.4f} (Acc) {history_epoch.history['val_accuracy'][-1]:.4f}\")\n",
    "        \n",
    "        if checkpoint:\n",
    "            checkpoint.step(model, history_epoch.history['val_accuracy'][-1])\n",
    "\n",
    "\n",
    "        ## Log the metrics to WandB\n",
    "        wandb.log(history_epoch.return_lasts())\n",
    "\n",
    "    return history_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_and_preds(model, dataloader):\n",
    "    \"\"\"\n",
    "    Gets the true and predicted labels for a given dataloader.\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    preds = []\n",
    "    ## Get every prediction and label\n",
    "    for X, Y in dataloader:\n",
    "        X = X.to(device).float()\n",
    "        with torch.no_grad():\n",
    "            pred = model(X)\n",
    "            pred = pred.softmax(-1).argmax(-1)\n",
    "            preds.extend(pred.cpu().numpy())\n",
    "            labels.extend(Y.numpy())\n",
    "    \n",
    "    return labels, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_labels_bundle_pth(model, dataset, dataloader):\n",
    "    \"\"\"\n",
    "    Plots the true labels and the predicted labels versus time.\n",
    "    \"\"\"\n",
    "    preds = []\n",
    "    labels = []\n",
    "    ## Get every prediction and label\n",
    "    for X, Y in dataloader:\n",
    "        X = X.to(device).float()\n",
    "        with torch.no_grad():\n",
    "            pred = model(X)\n",
    "            pred = pred.softmax(-1).argmax(-1)\n",
    "            preds.extend(pred.cpu().numpy())\n",
    "            labels.extend(Y.numpy())\n",
    "    \n",
    "    ## Plot the figure\n",
    "    plt.figure(figsize=(20,6))\n",
    "    utils.plot_labels(labels, preds, dataset.id_to_class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm_bundle_pth(model, dataset, dataloader, cmap='magma'):\n",
    "    \"\"\"\n",
    "    Plots the confusion matrix for a model trained with a dataset and dataloader.\n",
    "    \"\"\"\n",
    "    preds = []\n",
    "    labels = []\n",
    "    ## Get every prediction and label\n",
    "    for X, Y in dataloader:\n",
    "        X = X.to(device).float()\n",
    "        with torch.no_grad():\n",
    "            pred = model(X)\n",
    "            pred = pred.softmax(-1).argmax(-1)\n",
    "            preds.extend(pred.cpu().numpy())\n",
    "            labels.extend(Y.numpy())\n",
    "    \n",
    "    ## Plot confusion matrix\n",
    "    plt.figure(figsize=(8,8))\n",
    "    utils.plot_heatmaps_raw(confusion_matrix(labels, preds), precision=0, cmap=cmap)\n",
    "    plt.colorbar()\n",
    "    plt.xticks(range(len(dataset.id_to_class_dict)), dataset.id_to_class_dict.values(), rotation=90)\n",
    "    plt.yticks(range(len(dataset.id_to_class_dict)), dataset.id_to_class_dict.values(), rotation=0)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, preds, dataset, cmap='magma'):\n",
    "    \"\"\"\n",
    "    Plots the confusion matrix for a model trained with a dataset and dataloader.\n",
    "    \"\"\"\n",
    "    # plt.figure(figsize=(8,8))\n",
    "    utils.plot_heatmaps_raw(confusion_matrix(labels, preds), precision=0, cmap=cmap)\n",
    "    plt.colorbar()\n",
    "    plt.xticks(range(len(dataset.id_to_class_dict)), dataset.id_to_class_dict.values(), rotation=90)\n",
    "    plt.yticks(range(len(dataset.id_to_class_dict)), dataset.id_to_class_dict.values(), rotation=0)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.33 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.32<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">swept-snowflake-46</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jorgvt/test-pth\" target=\"_blank\">https://wandb.ai/jorgvt/test-pth</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jorgvt/test-pth/runs/3p4nyzov\" target=\"_blank\">https://wandb.ai/jorgvt/test-pth/runs/3p4nyzov</a><br/>\n",
       "                Run data is saved locally in <code>/home/jorgevi/SSD_IA3/Notebooks/wandb/run-20210705_122247-3p4nyzov</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 -> [Train] (Loss) 0.7389 (Acc) 0.6829 | [Val] (Loss) 0.6772 (Acc) 0.8618\n",
      "val_accuracy improved from -999999.0000 -> 0.8618. Model saved!.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 -> [Train] (Loss) 0.6661 (Acc) 0.6574 | [Val] (Loss) 0.6428 (Acc) 0.8834\n",
      "val_accuracy improved from 0.8618 -> 0.8834. Model saved!.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 -> [Train] (Loss) 0.6966 (Acc) 0.6551 | [Val] (Loss) 0.6168 (Acc) 0.9279\n",
      "val_accuracy improved from 0.8834 -> 0.9279. Model saved!.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 -> [Train] (Loss) 0.6666 (Acc) 0.6481 | [Val] (Loss) 0.6389 (Acc) 0.7608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 -> [Train] (Loss) 0.7034 (Acc) 0.6725 | [Val] (Loss) 0.6172 (Acc) 0.8305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 -> [Train] (Loss) 0.6772 (Acc) 0.6759 | [Val] (Loss) 1.0235 (Acc) 0.6046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 -> [Train] (Loss) 0.6596 (Acc) 0.7708 | [Val] (Loss) 0.7293 (Acc) 0.8185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 -> [Train] (Loss) 0.6037 (Acc) 0.7731 | [Val] (Loss) 0.8760 (Acc) 0.8173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 -> [Train] (Loss) 0.5253 (Acc) 0.7812 | [Val] (Loss) 0.9150 (Acc) 0.7452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 -> [Train] (Loss) 0.6506 (Acc) 0.7245 | [Val] (Loss) 1.2884 (Acc) 0.5457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 -> [Train] (Loss) 0.6112 (Acc) 0.7257 | [Val] (Loss) 0.7611 (Acc) 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 -> [Train] (Loss) 0.4606 (Acc) 0.8206 | [Val] (Loss) 1.1088 (Acc) 0.8281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 -> [Train] (Loss) 0.4900 (Acc) 0.7951 | [Val] (Loss) 0.8135 (Acc) 0.8101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 -> [Train] (Loss) 0.3903 (Acc) 0.8692 | [Val] (Loss) 2.2478 (Acc) 0.7308\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 23036<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc3060a33874f5fa66dd99dbfabadb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 2.89MB of 2.89MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/jorgevi/SSD_IA3/Notebooks/wandb/run-20210705_122247-3p4nyzov/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/jorgevi/SSD_IA3/Notebooks/wandb/run-20210705_122247-3p4nyzov/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>loss</td><td>0.39031</td></tr><tr><td>accuracy</td><td>0.86921</td></tr><tr><td>val_loss</td><td>2.24783</td></tr><tr><td>val_accuracy</td><td>0.73077</td></tr><tr><td>_runtime</td><td>144</td></tr><tr><td>_timestamp</td><td>1625480711</td></tr><tr><td>_step</td><td>14</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>loss</td><td>█▇▇▇▇▇▆▅▄▆▅▂▃▁</td></tr><tr><td>accuracy</td><td>▂▁▁▁▂▂▅▅▅▃▃▆▆█</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▃▁▂▂▄▂▃▂█</td></tr><tr><td>val_accuracy</td><td>▇▇█▅▆▂▆▆▅▁▅▆▆▄</td></tr><tr><td>_runtime</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇██</td></tr><tr><td>_timestamp</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇██</td></tr><tr><td>_step</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">swept-snowflake-46</strong>: <a href=\"https://wandb.ai/jorgvt/test-pth/runs/3p4nyzov\" target=\"_blank\">https://wandb.ai/jorgvt/test-pth/runs/3p4nyzov</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-3cbf3d30bed6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m## Train the model ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfiguration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m## Get the labels and predictions for the whole datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-36fb667b3d40>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(model, optimizer, loss_fn, trainloader, testloader, epochs, metrics, history, checkpoint, verbose)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mhistory_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mhistory_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ssd/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ssd/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ssd/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ssd/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SSD_IA3/Notebooks/Datasets.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m## Load data in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0;31m## Standarize data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ssd/lib/python3.8/site-packages/mne/epochs.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_baseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-219>\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self, out, picks, item, verbose)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ssd/lib/python3.8/site-packages/mne/epochs.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self, out, picks, item, verbose)\u001b[0m\n\u001b[1;32m   1359\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m                 \u001b[0;31m# faster to pre-allocate memory here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m                 \u001b[0mepoch_noproj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_epoch_from_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m                 epoch_noproj = self._detrend_offset_decim(\n\u001b[1;32m   1363\u001b[0m                     epoch_noproj, detrend_picks)\n",
      "\u001b[0;32m<decorator-gen-225>\u001b[0m in \u001b[0;36m_get_epoch_from_raw\u001b[0;34m(self, idx, verbose)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ssd/lib/python3.8/site-packages/mne/epochs.py\u001b[0m in \u001b[0;36m_get_epoch_from_raw\u001b[0;34m(self, idx, verbose)\u001b[0m\n\u001b[1;32m   2577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2578\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'    Getting epoch for %d-%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2579\u001b[0;31m         data = self._raw._check_bad_segment(start, stop, self.picks,\n\u001b[0m\u001b[1;32m   2580\u001b[0m                                             \u001b[0mreject_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreject_stop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2581\u001b[0m                                             self.reject_by_annotation)\n",
      "\u001b[0;32m~/miniconda3/envs/ssd/lib/python3.8/site-packages/mne/io/base.py\u001b[0m in \u001b[0;36m_check_bad_segment\u001b[0;34m(self, start, stop, picks, reject_start, reject_stop, reject_by_annotation)\u001b[0m\n\u001b[1;32m    502\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdescr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bad'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdescr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpicks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ssd/lib/python3.8/site-packages/mne/io/base.py\u001b[0m in \u001b[0;36m_getitem\u001b[0;34m(self, item, return_times)\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m             data = self._read_segment(start=start, stop=stop, sel=sel,\n\u001b[0m\u001b[1;32m    784\u001b[0m                                       projector=self._projector)\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-181>\u001b[0m in \u001b[0;36m_read_segment\u001b[0;34m(self, start, stop, sel, data_buffer, projector, verbose)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ssd/lib/python3.8/site-packages/mne/io/base.py\u001b[0m in \u001b[0;36m_read_segment\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0;31m# reindex back to original file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0morig_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_picks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneed_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m             _ReadSegmentFileProtector(self)._read_segment_file(\n\u001b[0m\u001b[1;32m    423\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_sl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m                 int(start_file), int(stop_file), cals, mult)\n",
      "\u001b[0;32m~/miniconda3/envs/ssd/lib/python3.8/site-packages/mne/io/base.py\u001b[0m in \u001b[0;36m_read_segment_file\u001b[0;34m(self, data, idx, fi, start, stop, cals, mult)\u001b[0m\n\u001b[1;32m   2066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2067\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_segment_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2068\u001b[0;31m         return self.__raw.__class__._read_segment_file(\n\u001b[0m\u001b[1;32m   2069\u001b[0m             self, data, idx, fi, start, stop, cals, mult)\n\u001b[1;32m   2070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ssd/lib/python3.8/site-packages/mne/io/edf/edf.py\u001b[0m in \u001b[0;36m_read_segment_file\u001b[0;34m(self, data, idx, fi, start, stop, cals, mult)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_segment_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;34m\"\"\"Read a chunk of raw data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         return _read_segment_file(data, idx, fi, start, stop,\n\u001b[0m\u001b[1;32m    142\u001b[0m                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_extras\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                                   cals, mult)\n",
      "\u001b[0;32m~/miniconda3/envs/ssd/lib/python3.8/site-packages/mne/io/edf/edf.py\u001b[0m in \u001b[0;36m_read_segment_file\u001b[0;34m(data, idx, fi, start, stop, raw_extras, filenames, cals, mult)\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0mch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmany_chunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mch_offsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mci\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mch_offsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mci\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mci\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtal_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m                     \u001b[0mtal_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with wandb.init(project='test-pth', entity='jorgvt', config = config):\n",
    "    configuration = wandb.config\n",
    "\n",
    "    ## Load the data ##\n",
    "    path_train = \"../Data/PSG1.edf\"\n",
    "    path_test = \"../Data/PSG2.edf\"\n",
    "    train = EDFData_PTH(path_train, channels=configuration.channels, binary=configuration.binary)\n",
    "    trainloader = torch.utils.data.DataLoader(train, batch_size = configuration.batch_size, drop_last=True)\n",
    "    test = EDFData_PTH(path_test, channels=configuration.channels, binary=configuration.binary)\n",
    "    testloader = torch.utils.data.DataLoader(test, batch_size = configuration.batch_size, drop_last=True)\n",
    "    sampling_rate = int(test.sampling_rate)\n",
    "\n",
    "    ## Define the model ##\n",
    "    model = TinySleepNet(sampling_rate, configuration.channels, classes=2)\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    ## Define the metrics ##\n",
    "    metrics = {\n",
    "    'accuracy':accuracy_fn\n",
    "    }\n",
    "\n",
    "    ## Define the checkpoint object ##\n",
    "    checkpoint = Checkpoint(os.path.join(wandb.run.dir,'model.pth'), 'val_accuracy', mode='max')\n",
    "\n",
    "    ## Train the model ##\n",
    "    h = train_fn(model, optimizer, loss_fn, trainloader, testloader, configuration.epochs, metrics, checkpoint=checkpoint)\n",
    "\n",
    "    ## Get the labels and predictions for the whole datasets\n",
    "    labels_train, preds_train = get_labels_and_preds(model, trainloader)\n",
    "    labels_test, preds_test = get_labels_and_preds(model, testloader)\n",
    "    \n",
    "    ## Create and log figures\n",
    "    ### Train\n",
    "    plt.figure(figsize=(20,6))\n",
    "    utils.plot_labels(preds_train, labels_train, label_mapper=train.id_to_class_dict)\n",
    "    wandb.log({\"Labels_Preds_Plot_Train\":wandb.Image(plt)})\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plot_cm(labels_train, preds_train, train)\n",
    "    wandb.log({\"Confusion_Matrix_Train\":wandb.Image(plt)})\n",
    "    ### Test\n",
    "    plt.figure(figsize=(20,6))\n",
    "    utils.plot_labels(preds_test, labels_test, label_mapper=train.id_to_class_dict)\n",
    "    wandb.log({\"Labels_Preds_Plot_Test\":wandb.Image(plt)})\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plot_cm(labels_test, preds_test, test)\n",
    "    wandb.log({\"Confusion_Matrix_Test\":wandb.Image(plt)})"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19dfd1d083436ef0c94dc83e82858078ce2d17debee98da79a4ad2d0556f4e62"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('ssd': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}